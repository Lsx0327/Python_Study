{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78769cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel, rbf_kernel\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Add parent directory to python path\n",
    "#PACKAGE_PARENT = '..'\n",
    "#SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser(__file__))))\n",
    "#sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "sys.path.append(r'E:\\Developer\\Python\\Myworkshop\\Python_Study\\机器学习\\Matrix Factorization\\Jupyter_notebook调试代码')\n",
    "from my_data_set import DataSet\n",
    "\n",
    "\n",
    "class GpMf():\n",
    "    def __init__(self, latent_dim, nb_data):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.nb_data = nb_data\n",
    "        #self.X = np.random.normal(0, 1e-3, (nb_data, latent_dim))   #a spherical Gaussian prior over the X\n",
    "        self.X = np.random.normal(0, 1e-2, (nb_data, latent_dim))   #a spherical Gaussian prior over the X\n",
    "        print(\"self.X:\",self.X,\"self.X.shape:\",self.X.shape)\n",
    "        self.lin_variance = 1.0\n",
    "        self.bias_variance = 0.11\n",
    "        self.white_variance = 5.0\n",
    "        self.y = None\n",
    "        self.rated_items = None\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"return the log likelihood of the model\"\"\"\n",
    "        Cj_invy, logDetC = self.invert_covariance()\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Nj = len(self.rated_items)\n",
    "        #P9 公式20\n",
    "        likelihood = - 0.5 * (Nj * np.log(2 * math.pi) + logDetC + yj.T.dot(Cj_invy))\n",
    "        return float(likelihood)\n",
    "\n",
    "    def invert_covariance(self, gradient=False, nonlinear =False, kernel=linear_kernel):\n",
    "        q = self.latent_dim\n",
    "        Nj = len(self.rated_items)\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        # Xj = np.asmatrix(self.X[int(self.rated_items), :])\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        s_n = self.white_variance\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        sigNoise = s_w / s_n\n",
    "\n",
    "        if Nj > q and not nonlinear: # we use the matrix inversion lemma\n",
    "            XTX = Xj.T * Xj\n",
    "            B = np.eye(q) + sigNoise * XTX\n",
    "            Binv = np.linalg.pinv(B)\n",
    "            _, logdetB = np.linalg.slogdet(B)\n",
    "            if gradient:\n",
    "                AinvX = (Xj - sigNoise * Xj * (Binv * XTX)) / s_n\n",
    "                AinvTr = (Nj - sigNoise * (np.multiply(Xj * Binv, Xj)).sum()) / s_n\n",
    "            Ainvy = (yj - sigNoise * Xj * (Binv * (Xj.T * yj))) / s_n\n",
    "            sumAinv = (np.ones((Nj, 1)) - sigNoise * Xj * (Binv * Xj.sum(axis=0).T)) / s_n  # this is Nx1\n",
    "            sumAinvSum = sumAinv.sum()\n",
    "            denom = 1 + s_b * sumAinvSum\n",
    "            fact = s_b / denom\n",
    "            if gradient:\n",
    "                CinvX = AinvX - fact * sumAinv * (sumAinv.T * Xj)\n",
    "                CinvSum = sumAinv - fact * sumAinv * sumAinvSum\n",
    "                CinvTr = AinvTr - fact * sumAinv.T * sumAinv\n",
    "\n",
    "            Cinvy = Ainvy - fact * sumAinv * float(sumAinv.T * yj)\n",
    "            if not gradient:\n",
    "                logdetA = Nj * np.log(s_n) + logdetB\n",
    "                logdetC = logdetA + np.log(denom)\n",
    "\n",
    "        else :\n",
    "            C = s_w * kernel(Xj, Xj)\n",
    "            C = C + s_b + s_n * np.eye(Nj)\n",
    "            Cinv = np.linalg.pinv(C)\n",
    "            Cinvy = Cinv * yj\n",
    "            if gradient:\n",
    "                CinvX = Cinv * Xj\n",
    "                CinvTr = np.trace(Cinv)\n",
    "                CinvSum = Cinv.sum(axis=1)\n",
    "            else:\n",
    "                _, logdetC = np.linalg.slogdet(C)\n",
    "\n",
    "        if gradient:\n",
    "            return Cinvy, CinvSum, CinvX, CinvTr\n",
    "        else:\n",
    "            return Cinvy, logdetC\n",
    "\n",
    "    def log_likelihood_grad(self, ):\n",
    "        \"\"\"Computes the gradient of the log likelihood\"\"\"\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        s_n = self.white_variance\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\", self.X[[0, 1, 2], :])\n",
    "        # print(\"self.rated_items:\",self.rated_items,type(self.rated_items),self.rated_items.shape)\n",
    "        #到这会出问题。\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\", self.X[self.rated_items,:])\n",
    "\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        # Xj = np.asmatrix(self.X[int(self.rated_items), :])\n",
    "        # print(\"invert_covariance----self.X[self.rated_items, :]:\",self.X[self.rated_items, :])\n",
    "        Cinvy, CinvSum, CinvX, CinvTr = self.invert_covariance(gradient=True)\n",
    "        covGradX = 0.5 * (Cinvy * (Cinvy.T * Xj) - CinvX)\n",
    "        gX = s_w * 2.0 * covGradX\n",
    "        gsigma_w = np.multiply(covGradX, Xj).sum()\n",
    "        CinvySum = Cinvy.sum()\n",
    "        CinvSumSum = CinvSum.sum()\n",
    "        gsigma_b = 0.5 * (CinvySum * CinvySum - CinvSumSum)\n",
    "        gsigma_n = 0.5 * (Cinvy.T * Cinvy - CinvTr)\n",
    "        return gX, float(gsigma_w), float(gsigma_b), float(gsigma_n)\n",
    "\n",
    "    def objective(self):\n",
    "        return -self.log_likelihood()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f792e",
   "metadata": {},
   "source": [
    "Fit代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6828d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset, model, nb_iter=10, seed=42, momentum=0.9):\n",
    "    data = dataset.get_df()\n",
    "    param_init = np.zeros((1, 3))\n",
    "    X_init = np.zeros(model.X.shape)\n",
    "    for iter in range(nb_iter):\n",
    "        print(\"iteration：\", iter)\n",
    "        tic = time.time()\n",
    "        # 随机数要做什么？\n",
    "        np.random.seed(seed=seed)\n",
    "        state = np.random.get_state()\n",
    "        #每次随机生成的都一样，详见test.py\n",
    "        users = np.random.permutation(dataset.get_users())\n",
    "        #print(\"users:\",users.shape)\n",
    "\n",
    "        for user in users:\n",
    "            #print(\"begin user\", user,  \"=========================\")\n",
    "            toc = time.time()\n",
    "            lr = 1e-4\n",
    "            y = dataset.get_ratings_user(user)\n",
    "            #print(\"the user:\",user)\n",
    "            #print(\"y:\",y)\n",
    "            # rated_items = dataset.get_items_user(user) - 1\n",
    "            rated_items = dataset.get_items_user(user)\n",
    "            #print(\"rated_items:\",rated_items,\"type:\",type(rated_items))\n",
    "            model.y = y\n",
    "            #Ronchy将rated_items ndnumpy格式变成list\n",
    "            rated_items = list(rated_items)\n",
    "            #========================================\n",
    "            model.rated_items = rated_items\n",
    "            grad_X, grad_w, grad_b, grad_n = model.log_likelihood_grad()\n",
    "            gradient_param = np.array([grad_w * model.lin_variance,\n",
    "                               grad_b * model.bias_variance,\n",
    "                               grad_n * model.white_variance])\n",
    "            param = np.log(np.array([model.lin_variance,\n",
    "                                     model.bias_variance,\n",
    "                                     model.white_variance]))\n",
    "            # update X\n",
    "            X = X_init[rated_items, :]\n",
    "            ar = lr * 10\n",
    "            X = X * momentum + grad_X * ar\n",
    "            X_init[rated_items, :] = X\n",
    "            model.X[rated_items, :] = model.X[rated_items, :] + X\n",
    "\n",
    "            # update variances\n",
    "            param_init = param_init * momentum + gradient_param * lr\n",
    "            param = param + param_init\n",
    "            model.lin_variance = np.exp(param[0, 0])\n",
    "            model.bias_variance = np.exp(param[0, 1])\n",
    "            model.white_variance = np.exp(param[0, 2])\n",
    "            #print(\"end user\", user, \"=========================\")\n",
    "\n",
    "        print(\"end iteration\", iter,  \"=========================\")\n",
    "        print(\"duration iteration\", time.time() - tic)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744ed97",
   "metadata": {},
   "source": [
    "Predict代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61494793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, test_items, model, dataset):\n",
    "    y = dataset.get_ratings_user(user)\n",
    "    # rated_items = dataset.get_items_user(user) - 1\n",
    "    rated_items = dataset.get_items_user(user)\n",
    "    rated_items = list(rated_items)\n",
    "    test_items = list(test_items)\n",
    "    model.rated_items = rated_items\n",
    "    model.y = y\n",
    "    X_test = np.asmatrix(model.X[test_items, :])\n",
    "    X = np.asmatrix(model.X[model.rated_items, :])\n",
    "    print(\"model.X[test_items, :]\",model.X[test_items, :].shape)\n",
    "    print(\"model.X[model.rated_items, :]\",model.X[model.rated_items, :].shape)\n",
    "    print(\"X\",X.shape)\n",
    "    print(\"X_test:\",X_test.shape)\n",
    "    Cinvy, CinvSum, CinvX, CinvTr = model.invert_covariance(gradient=True)\n",
    "    mean = model.lin_variance* X_test*(X.T*Cinvy) + Cinvy.sum() * model.bias_variance\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335469d",
   "metadata": {},
   "source": [
    "执行代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a56570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_weak(dataset, base_dim=5):\n",
    "    print('Fetch data set...')\n",
    "    # if dataset.dataset == \"movielens\":\n",
    "    #     norm_coeff = 1.6\n",
    "    #     print(\"norm_coeff:1.6------------\")\n",
    "    # else :\n",
    "    #     norm_coeff = 6.67\n",
    "    norm_coeff = 1.6\n",
    "    print('Data set fetched')\n",
    "    # print(\"Dataset desctiption\", dataset.get_description())\n",
    "    model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "    print('Fit the model...')\n",
    "    model = fit(dataset=dataset, model=model_init)\n",
    "    print('Model fitted')\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    test_users = dataset.get_users_test()\n",
    "\n",
    "    nb_users_test = len(test_users)\n",
    "    print(\"nb_users_test\", nb_users_test)\n",
    "    count = 0\n",
    "    for user in test_users:\n",
    "        prediction = predict(user, dataset.get_item_test(user), model, dataset)\n",
    "        if prediction > dataset.high_rating:\n",
    "            prediction = dataset.high_rating\n",
    "        if prediction < dataset.low_rating:\n",
    "            prediction = dataset.low_rating\n",
    "        predictions.append(prediction)\n",
    "        rating = dataset.get_rating_test(user)\n",
    "        true_ratings.append(rating)\n",
    "        count += 1\n",
    "        #print(count, \"over \", nb_users_test, \"users\")\n",
    "    predictions = np.asarray(predictions)\n",
    "    true_ratings = np.asarray(true_ratings)\n",
    "    #误差计算\n",
    "    rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "    nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "    print(\"rmse\", rmse)\n",
    "    print(\"nmae\", nmae)\n",
    "    return float(rmse), float(nmae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c47314",
   "metadata": {},
   "source": [
    "画图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb349e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_vs_latent_dims():\n",
    "    base_dims = range(3, 10)  #latent feature ,3的时候最好\n",
    "    rmse_res = []\n",
    "        #0.9192805345815771, 0.9191762806556765, 0.9298582192495648, 0.9264887573748214, 0.942721413670847,\n",
    "        #0.9464276649204383, 0.9619938797137044, 0.959524838407498, 0.9637647705458857, 0.9654112679112156,\n",
    "        #0.964014562524729, 0.9828162923399141, 0.9791815989138641, 0.9755912980143179, 0.9909916313775403]\n",
    "    nmae_res = []\n",
    "        #0.44971496453721255, 0.44916990674349777, 0.4520802986328138, 0.45121143493891314, 0.45841600020196077,\n",
    "        #0.4600831341641973, 0.46819195277564857, 0.4653186575931832, 0.4675059307434209, 0.46521752440367997,\n",
    "        #0.4693989965956004, 0.4749311584164483, 0.47302261002602103, 0.47072878663284334, 0.4775780782441432]\n",
    "\n",
    "    if not len(rmse_res):\n",
    "        dataset_Corner = DataSet(dataset=\"Corner\", size=\"14\")\n",
    "        for dim in base_dims:\n",
    "            print(\"the latent-feature:\",dim)\n",
    "            (rmse, nmae) = perf_weak(dataset=dataset_Corner, base_dim=dim)\n",
    "            rmse_res.append(rmse)\n",
    "            nmae_res.append(nmae)\n",
    "\n",
    "        print(rmse_res)\n",
    "        print(nmae_res)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, rmse_res, marker='.')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('RMSE (MovieLens 100k)')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, nmae_res, marker='*')\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('NMAE (MovieLens 100k)')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ea63d",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('START')\n",
    "    #perf_weak(dataset=DataSet(dataset=\"Corner\", size=\"14\"))\n",
    "\n",
    "    # plot_errors_vs_latent_dims()\n",
    "    \n",
    "    \n",
    "    print('END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126fa1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.low_rating: 2.301 self.high_rating: 8.292\n",
      "self.item_index_range 13\n",
      "self.df_train:        row col  value\n",
      "0        0   0  3.335\n",
      "1        1   0  3.311\n",
      "2        2   0  4.600\n",
      "3        3   0  5.083\n",
      "4        4   0  6.327\n",
      "...    ...  ..    ...\n",
      "4207  1399   2  4.459\n",
      "4208  1400   2  5.777\n",
      "4209  1401   2  4.542\n",
      "4210  1402   2  3.776\n",
      "4211  1403   2  5.067\n",
      "\n",
      "[4212 rows x 3 columns]\n",
      "self.df_test:         row col  value\n",
      "4212      0   3  2.694\n",
      "4213      1   3  5.445\n",
      "4214      2   3  2.642\n",
      "4215      3   3  5.798\n",
      "4216      4   3  3.563\n",
      "...     ...  ..    ...\n",
      "18247  1399  12  5.635\n",
      "18248  1400  12  4.573\n",
      "18249  1401  12  7.132\n",
      "18250  1402  12  6.569\n",
      "18251  1403  12  4.208\n",
      "\n",
      "[14040 rows x 3 columns]\n",
      "Fetch data set...\n",
      "Data set fetched\n",
      "self.X: [[ 2.25437016e-02  5.75256982e-03 -6.93134937e-03 -6.40614585e-03\n",
      "  -3.82232967e-03]\n",
      " [ 4.29087555e-03 -6.41804138e-04 -6.36960297e-03  2.62669246e-02\n",
      "   7.02731915e-03]\n",
      " [-1.42742612e-02  1.64015157e-02 -1.05018104e-02 -7.22435608e-03\n",
      "   6.74802835e-03]\n",
      " [ 7.39925808e-04  4.29207433e-03  3.54398901e-03  1.49098495e-02\n",
      "  -3.66196602e-03]\n",
      " [ 4.59773707e-03 -1.69269988e-02 -1.73213085e-02 -2.03331279e-02\n",
      "  -5.23266724e-03]\n",
      " [ 2.07543692e-02  5.42733183e-03  6.18518496e-04 -1.37842195e-02\n",
      "  -2.59733986e-03]\n",
      " [-1.04413147e-02 -1.23519883e-02  3.50005401e-04 -1.09366193e-02\n",
      "  -8.43348826e-03]\n",
      " [-3.06256679e-02 -1.03992590e-02 -7.92194951e-03  3.82821389e-03\n",
      "   3.97179250e-03]\n",
      " [-1.91372590e-03  1.33218829e-02 -8.94230875e-03 -9.50566124e-03\n",
      "   8.05120254e-03]\n",
      " [ 3.31586818e-03 -1.66403156e-02  2.69815630e-03 -1.85855322e-03\n",
      "  -5.28123740e-03]\n",
      " [-8.92131303e-03  7.39812551e-03 -8.19523976e-03  6.12047465e-03\n",
      "  -3.94418680e-05]\n",
      " [-1.06517741e-02  4.96161622e-04  1.83784034e-02  1.16612678e-02\n",
      "   3.08085122e-03]\n",
      " [ 1.65082152e-02 -5.52553322e-03  5.19159895e-03 -1.86002840e-03\n",
      "   2.47373734e-02]] self.X.shape: (13, 5)\n",
      "Fit the model...\n",
      "iteration： 0\n",
      "end iteration 0 =========================\n",
      "duration iteration 26.66329550743103\n",
      "iteration： 1\n",
      "end iteration 1 =========================\n",
      "duration iteration 63.777201652526855\n",
      "iteration： 2\n",
      "end iteration 2 =========================\n",
      "duration iteration 25.968382596969604\n",
      "iteration： 3\n",
      "end iteration 3 =========================\n",
      "duration iteration 26.114598274230957\n",
      "iteration： 4\n",
      "end iteration 4 =========================\n",
      "duration iteration 25.915627002716064\n",
      "iteration： 5\n",
      "end iteration 5 =========================\n",
      "duration iteration 25.534007787704468\n",
      "iteration： 6\n",
      "end iteration 6 =========================\n",
      "duration iteration 25.514525651931763\n",
      "iteration： 7\n",
      "end iteration 7 =========================\n",
      "duration iteration 26.370677947998047\n",
      "iteration： 8\n",
      "end iteration 8 =========================\n",
      "duration iteration 32.93769645690918\n",
      "iteration： 9\n",
      "end iteration 9 =========================\n",
      "duration iteration 28.03421640396118\n",
      "Model fitted\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet(dataset=\"Corner\", size=\"14\")\n",
    "base_dim = 5\n",
    "\n",
    "print('Fetch data set...')\n",
    "# if dataset.dataset == \"movielens\":\n",
    "#     norm_coeff = 1.6\n",
    "#     print(\"norm_coeff:1.6------------\")\n",
    "# else :\n",
    "#     norm_coeff = 6.67\n",
    "norm_coeff = 1.6\n",
    "print('Data set fetched')\n",
    "# print(\"Dataset desctiption\", dataset.get_description())\n",
    "model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "print('Fit the model...')\n",
    "model = fit(dataset=dataset, model=model_init)\n",
    "print('Model fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c85a5",
   "metadata": {},
   "source": [
    "做Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_ratings = []\n",
    "test_users = dataset.get_users_test()\n",
    "\n",
    "nb_users_test = len(test_users)\n",
    "print(\"nb_users_test\", nb_users_test)\n",
    "count = 0\n",
    "for user in test_users:\n",
    "    prediction = predict(user, dataset.get_item_test(user), model, dataset)\n",
    "    \n",
    "    #print(\"dataset.get_item_test(user):\",dataset.get_item_test(user),dataset.get_item_test(user).shape)\n",
    "    #print(\"prediction:\",prediction,type(prediction))\n",
    "#numpy 如何将大于或小于阈值的值替换为给定的阈值\n",
    "#https://www.jianshu.com/p/a454b0657c4a\n",
    "#     if prediction > dataset.high_rating:\n",
    "#         prediction = dataset.high_rating\n",
    "#     if prediction < dataset.low_rating:\n",
    "#         prediction = dataset.low_rating\n",
    "    predictions.append(prediction)\n",
    "    rating = dataset.get_rating_test(user)\n",
    "    true_ratings.append(rating)\n",
    "    count += 1\n",
    "    #print(count, \"over \", nb_users_test, \"users\")\n",
    "predictions = np.asarray(predictions)\n",
    "true_ratings = np.asarray(true_ratings)\n",
    "#误差计算\n",
    "rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "print(\"rmse\", rmse)\n",
    "print(\"nmae\", nmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cbb41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
