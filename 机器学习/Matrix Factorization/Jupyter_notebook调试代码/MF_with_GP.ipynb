{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78769cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel, rbf_kernel\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Add parent directory to python path\n",
    "#PACKAGE_PARENT = '..'\n",
    "#SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser(__file__))))\n",
    "#sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "sys.path.append(r'E:\\Developer\\Python\\Myworkshop\\Python_Study\\机器学习\\Matrix Factorization\\Jupyter_notebook调试代码')\n",
    "from my_data_set import DataSet\n",
    "\n",
    "\n",
    "class GpMf():\n",
    "    def __init__(self, latent_dim, nb_data):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.nb_data = nb_data\n",
    "        #self.X = np.random.normal(0, 1e-3, (nb_data, latent_dim))   #a spherical Gaussian prior over the X\n",
    "        self.X = np.random.normal(0, 1e-2, (nb_data, latent_dim))   #a spherical Gaussian prior over the X\n",
    "        print(\"self.X:\",self.X,\"self.X.shape:\",self.X.shape)\n",
    "        self.lin_variance = 1.0\n",
    "        self.bias_variance = 0.11\n",
    "        self.white_variance = 5.0\n",
    "        self.y = None\n",
    "        self.rated_items = None\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"return the log likelihood of the model\"\"\"\n",
    "        Cj_invy, logDetC = self.invert_covariance()\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Nj = len(self.rated_items)\n",
    "        #P9 公式20\n",
    "        likelihood = - 0.5 * (Nj * np.log(2 * math.pi) + logDetC + yj.T.dot(Cj_invy))\n",
    "        return float(likelihood)\n",
    "\n",
    "    def invert_covariance(self, gradient=False, nonlinear =False, kernel=linear_kernel):\n",
    "        q = self.latent_dim\n",
    "        Nj = len(self.rated_items)\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        # Xj = np.asmatrix(self.X[int(self.rated_items), :])\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        s_n = self.white_variance\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        sigNoise = s_w / s_n\n",
    "\n",
    "        if Nj > q and not nonlinear: # we use the matrix inversion lemma\n",
    "            XTX = Xj.T * Xj\n",
    "            B = np.eye(q) + sigNoise * XTX\n",
    "            Binv = np.linalg.pinv(B)\n",
    "            _, logdetB = np.linalg.slogdet(B)\n",
    "            if gradient:\n",
    "                AinvX = (Xj - sigNoise * Xj * (Binv * XTX)) / s_n\n",
    "                AinvTr = (Nj - sigNoise * (np.multiply(Xj * Binv, Xj)).sum()) / s_n\n",
    "            Ainvy = (yj - sigNoise * Xj * (Binv * (Xj.T * yj))) / s_n\n",
    "            sumAinv = (np.ones((Nj, 1)) - sigNoise * Xj * (Binv * Xj.sum(axis=0).T)) / s_n  # this is Nx1\n",
    "            sumAinvSum = sumAinv.sum()\n",
    "            denom = 1 + s_b * sumAinvSum\n",
    "            fact = s_b / denom\n",
    "            if gradient:\n",
    "                CinvX = AinvX - fact * sumAinv * (sumAinv.T * Xj)\n",
    "                CinvSum = sumAinv - fact * sumAinv * sumAinvSum\n",
    "                CinvTr = AinvTr - fact * sumAinv.T * sumAinv\n",
    "\n",
    "            Cinvy = Ainvy - fact * sumAinv * float(sumAinv.T * yj)\n",
    "            if not gradient:\n",
    "                logdetA = Nj * np.log(s_n) + logdetB\n",
    "                logdetC = logdetA + np.log(denom)\n",
    "\n",
    "        else :\n",
    "            C = s_w * kernel(Xj, Xj)\n",
    "            C = C + s_b + s_n * np.eye(Nj)\n",
    "            Cinv = np.linalg.pinv(C)\n",
    "            Cinvy = Cinv * yj\n",
    "            if gradient:\n",
    "                CinvX = Cinv * Xj\n",
    "                CinvTr = np.trace(Cinv)\n",
    "                CinvSum = Cinv.sum(axis=1)\n",
    "            else:\n",
    "                _, logdetC = np.linalg.slogdet(C)\n",
    "\n",
    "        if gradient:\n",
    "            return Cinvy, CinvSum, CinvX, CinvTr\n",
    "        else:\n",
    "            return Cinvy, logdetC\n",
    "\n",
    "    def log_likelihood_grad(self, ):\n",
    "        \"\"\"Computes the gradient of the log likelihood\"\"\"\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        s_n = self.white_variance\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\", self.X[[0, 1, 2], :])\n",
    "        # print(\"self.rated_items:\",self.rated_items,type(self.rated_items),self.rated_items.shape)\n",
    "        #到这会出问题。\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\", self.X[self.rated_items,:])\n",
    "\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        # Xj = np.asmatrix(self.X[int(self.rated_items), :])\n",
    "        # print(\"invert_covariance----self.X[self.rated_items, :]:\",self.X[self.rated_items, :])\n",
    "        Cinvy, CinvSum, CinvX, CinvTr = self.invert_covariance(gradient=True)\n",
    "        covGradX = 0.5 * (Cinvy * (Cinvy.T * Xj) - CinvX)\n",
    "        gX = s_w * 2.0 * covGradX\n",
    "        gsigma_w = np.multiply(covGradX, Xj).sum()\n",
    "        CinvySum = Cinvy.sum()\n",
    "        CinvSumSum = CinvSum.sum()\n",
    "        gsigma_b = 0.5 * (CinvySum * CinvySum - CinvSumSum)\n",
    "        gsigma_n = 0.5 * (Cinvy.T * Cinvy - CinvTr)\n",
    "        return gX, float(gsigma_w), float(gsigma_b), float(gsigma_n)\n",
    "\n",
    "    def objective(self):\n",
    "        return -self.log_likelihood()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f792e",
   "metadata": {},
   "source": [
    "Fit代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6828d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset, model, nb_iter=10, seed=42, momentum=0.9):\n",
    "    data = dataset.get_df()\n",
    "    param_init = np.zeros((1, 3))\n",
    "    X_init = np.zeros(model.X.shape)\n",
    "    for iter in range(nb_iter):\n",
    "        print(\"iteration：\", iter)\n",
    "        tic = time.time()\n",
    "        # 随机数要做什么？\n",
    "        np.random.seed(seed=seed)\n",
    "        state = np.random.get_state()\n",
    "        #每次随机生成的都一样，详见test.py\n",
    "        users = np.random.permutation(dataset.get_users())\n",
    "        #print(\"users:\",users.shape)\n",
    "\n",
    "        for user in users:\n",
    "            #print(\"begin user\", user,  \"=========================\")\n",
    "            toc = time.time()\n",
    "            lr = 1e-4\n",
    "            y = dataset.get_ratings_user(user)\n",
    "            #print(\"the user:\",user)\n",
    "            #print(\"y:\",y)\n",
    "            # rated_items = dataset.get_items_user(user) - 1\n",
    "            rated_items = dataset.get_items_user(user)\n",
    "            #print(\"rated_items:\",rated_items,\"type:\",type(rated_items))\n",
    "            model.y = y\n",
    "            #Ronchy将rated_items ndnumpy格式变成list\n",
    "            rated_items = list(rated_items)\n",
    "            #========================================\n",
    "            model.rated_items = rated_items\n",
    "            grad_X, grad_w, grad_b, grad_n = model.log_likelihood_grad()\n",
    "            gradient_param = np.array([grad_w * model.lin_variance,\n",
    "                               grad_b * model.bias_variance,\n",
    "                               grad_n * model.white_variance])\n",
    "            param = np.log(np.array([model.lin_variance,\n",
    "                                     model.bias_variance,\n",
    "                                     model.white_variance]))\n",
    "            # update X\n",
    "            X = X_init[rated_items, :]\n",
    "            ar = lr * 10\n",
    "            X = X * momentum + grad_X * ar\n",
    "            X_init[rated_items, :] = X\n",
    "            model.X[rated_items, :] = model.X[rated_items, :] + X\n",
    "\n",
    "            # update variances\n",
    "            param_init = param_init * momentum + gradient_param * lr\n",
    "            param = param + param_init\n",
    "            model.lin_variance = np.exp(param[0, 0])\n",
    "            model.bias_variance = np.exp(param[0, 1])\n",
    "            model.white_variance = np.exp(param[0, 2])\n",
    "            #print(\"end user\", user, \"=========================\")\n",
    "\n",
    "        print(\"end iteration\", iter,  \"=========================\")\n",
    "        print(\"duration iteration\", time.time() - tic)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744ed97",
   "metadata": {},
   "source": [
    "Predict代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61494793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, test_items, model, dataset):\n",
    "    y = dataset.get_ratings_user(user)\n",
    "    # rated_items = dataset.get_items_user(user) - 1\n",
    "    rated_items = dataset.get_items_user(user)\n",
    "    rated_items = list(rated_items)\n",
    "    test_items = list(test_items)\n",
    "    model.rated_items = rated_items\n",
    "    model.y = y\n",
    "    X_test = np.asmatrix(model.X[test_items, :])\n",
    "    X = np.asmatrix(model.X[model.rated_items, :])\n",
    "    print(\"model.X[test_items, :]\",model.X[test_items, :].shape)\n",
    "    print(\"model.X[model.rated_items, :]\",model.X[model.rated_items, :].shape)\n",
    "    print(\"X\",X.shape)\n",
    "    print(\"X_test:\",X_test.shape)\n",
    "    Cinvy, CinvSum, CinvX, CinvTr = model.invert_covariance(gradient=True)\n",
    "    mean = model.lin_variance* X_test*(X.T*Cinvy) + Cinvy.sum() * model.bias_variance\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335469d",
   "metadata": {},
   "source": [
    "执行代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a56570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_weak(dataset, base_dim=5):\n",
    "    print('Fetch data set...')\n",
    "    # if dataset.dataset == \"movielens\":\n",
    "    #     norm_coeff = 1.6\n",
    "    #     print(\"norm_coeff:1.6------------\")\n",
    "    # else :\n",
    "    #     norm_coeff = 6.67\n",
    "    norm_coeff = 1.6\n",
    "    print('Data set fetched')\n",
    "    # print(\"Dataset desctiption\", dataset.get_description())\n",
    "    model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "    print('Fit the model...')\n",
    "    model = fit(dataset=dataset, model=model_init)\n",
    "    print('Model fitted')\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    test_users = dataset.get_users_test()\n",
    "\n",
    "    nb_users_test = len(test_users)\n",
    "    print(\"nb_users_test\", nb_users_test)\n",
    "    count = 0\n",
    "    for user in test_users:\n",
    "        prediction = predict(user, dataset.get_item_test(user), model, dataset)\n",
    "        if prediction > dataset.high_rating:\n",
    "            prediction = dataset.high_rating\n",
    "        if prediction < dataset.low_rating:\n",
    "            prediction = dataset.low_rating\n",
    "        predictions.append(prediction)\n",
    "        rating = dataset.get_rating_test(user)\n",
    "        true_ratings.append(rating)\n",
    "        count += 1\n",
    "        #print(count, \"over \", nb_users_test, \"users\")\n",
    "    predictions = np.asarray(predictions)\n",
    "    true_ratings = np.asarray(true_ratings)\n",
    "    #误差计算\n",
    "    rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "    nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "    print(\"rmse\", rmse)\n",
    "    print(\"nmae\", nmae)\n",
    "    return float(rmse), float(nmae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c47314",
   "metadata": {},
   "source": [
    "画图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb349e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_vs_latent_dims():\n",
    "    base_dims = range(3, 10)  #latent feature ,3的时候最好\n",
    "    rmse_res = []\n",
    "        #0.9192805345815771, 0.9191762806556765, 0.9298582192495648, 0.9264887573748214, 0.942721413670847,\n",
    "        #0.9464276649204383, 0.9619938797137044, 0.959524838407498, 0.9637647705458857, 0.9654112679112156,\n",
    "        #0.964014562524729, 0.9828162923399141, 0.9791815989138641, 0.9755912980143179, 0.9909916313775403]\n",
    "    nmae_res = []\n",
    "        #0.44971496453721255, 0.44916990674349777, 0.4520802986328138, 0.45121143493891314, 0.45841600020196077,\n",
    "        #0.4600831341641973, 0.46819195277564857, 0.4653186575931832, 0.4675059307434209, 0.46521752440367997,\n",
    "        #0.4693989965956004, 0.4749311584164483, 0.47302261002602103, 0.47072878663284334, 0.4775780782441432]\n",
    "\n",
    "    if not len(rmse_res):\n",
    "        dataset_Corner = DataSet(dataset=\"Corner\", size=\"14\")\n",
    "        for dim in base_dims:\n",
    "            print(\"the latent-feature:\",dim)\n",
    "            (rmse, nmae) = perf_weak(dataset=dataset_Corner, base_dim=dim)\n",
    "            rmse_res.append(rmse)\n",
    "            nmae_res.append(nmae)\n",
    "\n",
    "        print(rmse_res)\n",
    "        print(nmae_res)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, rmse_res, marker='.')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('RMSE (MovieLens 100k)')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, nmae_res, marker='*')\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('NMAE (MovieLens 100k)')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ea63d",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('START')\n",
    "    #perf_weak(dataset=DataSet(dataset=\"Corner\", size=\"14\"))\n",
    "\n",
    "    # plot_errors_vs_latent_dims()\n",
    "    \n",
    "    \n",
    "    print('END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126fa1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.low_rating: 2.301 self.high_rating: 8.292\n",
      "self.item_index_range 13\n",
      "self.df_train:        row col  value\n",
      "0        0   0  3.335\n",
      "1        1   0  3.311\n",
      "2        2   0  4.600\n",
      "3        3   0  5.083\n",
      "4        4   0  6.327\n",
      "...    ...  ..    ...\n",
      "4207  1399   2  4.459\n",
      "4208  1400   2  5.777\n",
      "4209  1401   2  4.542\n",
      "4210  1402   2  3.776\n",
      "4211  1403   2  5.067\n",
      "\n",
      "[4212 rows x 3 columns]\n",
      "self.df_test:         row col  value\n",
      "4212      0   3  2.694\n",
      "4213      1   3  5.445\n",
      "4214      2   3  2.642\n",
      "4215      3   3  5.798\n",
      "4216      4   3  3.563\n",
      "...     ...  ..    ...\n",
      "18247  1399  12  5.635\n",
      "18248  1400  12  4.573\n",
      "18249  1401  12  7.132\n",
      "18250  1402  12  6.569\n",
      "18251  1403  12  4.208\n",
      "\n",
      "[14040 rows x 3 columns]\n",
      "Fetch data set...\n",
      "Data set fetched\n",
      "self.X: [[ 2.10874497e-02  7.36356800e-03  3.53292285e-03 -1.00602514e-02\n",
      "   8.91724611e-03]\n",
      " [ 1.98516281e-03 -1.05206026e-02  2.45447484e-02  2.35480335e-02\n",
      "   3.79695296e-03]\n",
      " [-5.07221241e-04 -1.34449421e-03  4.25717285e-03  1.29091368e-02\n",
      "  -1.68703430e-02]\n",
      " [ 7.11110099e-03 -1.57277748e-02 -1.29509253e-02  3.25934657e-03\n",
      "  -3.79644490e-03]\n",
      " [-4.44142809e-03  1.60691330e-02  1.07079490e-02 -7.99932434e-03\n",
      "   6.52332533e-03]\n",
      " [-6.36711908e-03  1.03609386e-02  1.40589960e-02 -6.96958073e-03\n",
      "   2.16929748e-03]\n",
      " [ 8.94114291e-04  6.83738804e-03  9.73232985e-05 -1.03321638e-02\n",
      "  -8.73154188e-03]\n",
      " [-3.76996413e-03 -1.61669046e-02 -1.41789971e-03  1.11516223e-02\n",
      "   5.84523787e-03]\n",
      " [-9.16626064e-04  6.62804513e-03  1.31600667e-03 -6.68089226e-03\n",
      "   6.81326494e-03]\n",
      " [ 9.65976658e-03  1.16992366e-02 -1.46332332e-02 -2.27076941e-03\n",
      "  -6.78258462e-03]\n",
      " [ 4.70403287e-03  1.08452600e-02  2.18775816e-04  2.21600558e-03\n",
      "  -7.69615406e-03]\n",
      " [-9.50197489e-03  1.89256051e-02  2.46893911e-02 -1.63105103e-02\n",
      "  -1.26506504e-02]\n",
      " [-1.32237896e-02 -5.79481934e-03 -1.86189090e-02  1.31037542e-02\n",
      "   7.55167002e-03]] self.X.shape: (13, 5)\n",
      "Fit the model...\n",
      "iteration： 0\n",
      "end iteration 0 =========================\n",
      "duration iteration 13.147968053817749\n",
      "iteration： 1\n",
      "end iteration 1 =========================\n",
      "duration iteration 12.883772611618042\n",
      "iteration： 2\n",
      "end iteration 2 =========================\n",
      "duration iteration 13.842435121536255\n",
      "iteration： 3\n",
      "end iteration 3 =========================\n",
      "duration iteration 14.95433259010315\n",
      "iteration： 4\n",
      "end iteration 4 =========================\n",
      "duration iteration 13.134470224380493\n",
      "iteration： 5\n",
      "end iteration 5 =========================\n",
      "duration iteration 12.517780303955078\n",
      "iteration： 6\n",
      "end iteration 6 =========================\n",
      "duration iteration 12.500252962112427\n",
      "iteration： 7\n",
      "end iteration 7 =========================\n",
      "duration iteration 19.914346933364868\n",
      "iteration： 8\n",
      "end iteration 8 =========================\n",
      "duration iteration 26.919651746749878\n",
      "iteration： 9\n",
      "end iteration 9 =========================\n",
      "duration iteration 26.002947568893433\n",
      "Model fitted\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet(dataset=\"Corner\", size=\"14\")\n",
    "base_dim = 5\n",
    "\n",
    "print('Fetch data set...')\n",
    "# if dataset.dataset == \"movielens\":\n",
    "#     norm_coeff = 1.6\n",
    "#     print(\"norm_coeff:1.6------------\")\n",
    "# else :\n",
    "#     norm_coeff = 6.67\n",
    "norm_coeff = 1.6\n",
    "print('Data set fetched')\n",
    "# print(\"Dataset desctiption\", dataset.get_description())\n",
    "model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "print('Fit the model...')\n",
    "model = fit(dataset=dataset, model=model_init)\n",
    "print('Model fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c85a5",
   "metadata": {},
   "source": [
    "做Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d934c978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_users_test 1404\n",
      "model.X[test_items, :] (10, 5)\n",
      "model.X[model.rated_items, :] (3, 5)\n",
      "X (3, 5)\n",
      "X_test: (10, 5)\n",
      "dataset.get_item_test(user): 4212      3\n",
      "5616      4\n",
      "7020      5\n",
      "8424      6\n",
      "9828      7\n",
      "11232     8\n",
      "12636     9\n",
      "14040    10\n",
      "15444    11\n",
      "16848    12\n",
      "Name: col, dtype: object (10,)\n",
      "prediction: [[0.02360478]\n",
      " [0.02422742]\n",
      " [0.02757817]\n",
      " [0.01971576]\n",
      " [0.03096909]\n",
      " [0.02051759]\n",
      " [0.01736367]\n",
      " [0.02966995]\n",
      " [0.02881323]\n",
      " [0.01163564]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.get_item_test(user):\u001b[39m\u001b[38;5;124m\"\u001b[39m,dataset\u001b[38;5;241m.\u001b[39mget_item_test(user),dataset\u001b[38;5;241m.\u001b[39mget_item_test(user)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m,prediction)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhigh_rating\u001b[49m:\n\u001b[0;32m     14\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mhigh_rating\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m<\u001b[39m dataset\u001b[38;5;241m.\u001b[39mlow_rating:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "true_ratings = []\n",
    "test_users = dataset.get_users_test()\n",
    "\n",
    "nb_users_test = len(test_users)\n",
    "print(\"nb_users_test\", nb_users_test)\n",
    "count = 0\n",
    "for user in test_users:\n",
    "    prediction = predict(user, dataset.get_item_test(user), model, dataset)\n",
    "    \n",
    "    print(\"dataset.get_item_test(user):\",dataset.get_item_test(user),dataset.get_item_test(user).shape)\n",
    "    print(\"prediction:\",prediction)\n",
    "    if prediction > dataset.high_rating:\n",
    "        prediction = dataset.high_rating\n",
    "    if prediction < dataset.low_rating:\n",
    "        prediction = dataset.low_rating\n",
    "    predictions.append(prediction)\n",
    "    rating = dataset.get_rating_test(user)\n",
    "    true_ratings.append(rating)\n",
    "    count += 1\n",
    "    #print(count, \"over \", nb_users_test, \"users\")\n",
    "predictions = np.asarray(predictions)\n",
    "true_ratings = np.asarray(true_ratings)\n",
    "#误差计算\n",
    "rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "print(\"rmse\", rmse)\n",
    "print(\"nmae\", nmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a3aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
