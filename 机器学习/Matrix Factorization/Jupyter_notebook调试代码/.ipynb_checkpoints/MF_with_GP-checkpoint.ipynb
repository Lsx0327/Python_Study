{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78769cb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Add parent directory to python path\u001b[39;00m\n\u001b[0;32m     12\u001b[0m PACKAGE_PARENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 13\u001b[0m SCRIPT_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;18;43m__file__\u001b[39;49m))))\n\u001b[0;32m     14\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SCRIPT_DIR, PACKAGE_PARENT)))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_data_set\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataSet\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel, rbf_kernel\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Add parent directory to python path\n",
    "PACKAGE_PARENT = '..'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser(__file__))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "from my_data_set import DataSet\n",
    "\n",
    "\n",
    "class GpMf():\n",
    "    def __init__(self, latent_dim, nb_data):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.nb_data = nb_data\n",
    "        #self.X = np.random.normal(0, 1e-3, (nb_data, latent_dim))   #a spherical Gaussian prior over the X\n",
    "        self.X = np.random.normal(0, 1e-2, (nb_data, latent_dim))   #a spherical Gaussian prior over the X\n",
    "        print(\"self.X:\",self.X,\"self.X.shape:\",self.X.shape)\n",
    "        self.lin_variance = 1.0\n",
    "        self.bias_variance = 0.11\n",
    "        self.white_variance = 5.0\n",
    "        self.y = None\n",
    "        self.rated_items = None\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"return the log likelihood of the model\"\"\"\n",
    "        Cj_invy, logDetC = self.invert_covariance()\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Nj = len(self.rated_items)\n",
    "        #P9 公式20\n",
    "        likelihood = - 0.5 * (Nj * np.log(2 * math.pi) + logDetC + yj.T.dot(Cj_invy))\n",
    "        return float(likelihood)\n",
    "\n",
    "    def invert_covariance(self, gradient=False, nonlinear =False, kernel=linear_kernel):\n",
    "        q = self.latent_dim\n",
    "        Nj = len(self.rated_items)\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        # Xj = np.asmatrix(self.X[int(self.rated_items), :])\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        s_n = self.white_variance\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        sigNoise = s_w / s_n\n",
    "\n",
    "        if Nj > q and not nonlinear: # we use the matrix inversion lemma\n",
    "            XTX = Xj.T * Xj\n",
    "            B = np.eye(q) + sigNoise * XTX\n",
    "            Binv = np.linalg.pinv(B)\n",
    "            _, logdetB = np.linalg.slogdet(B)\n",
    "            if gradient:\n",
    "                AinvX = (Xj - sigNoise * Xj * (Binv * XTX)) / s_n\n",
    "                AinvTr = (Nj - sigNoise * (np.multiply(Xj * Binv, Xj)).sum()) / s_n\n",
    "            Ainvy = (yj - sigNoise * Xj * (Binv * (Xj.T * yj))) / s_n\n",
    "            sumAinv = (np.ones((Nj, 1)) - sigNoise * Xj * (Binv * Xj.sum(axis=0).T)) / s_n  # this is Nx1\n",
    "            sumAinvSum = sumAinv.sum()\n",
    "            denom = 1 + s_b * sumAinvSum\n",
    "            fact = s_b / denom\n",
    "            if gradient:\n",
    "                CinvX = AinvX - fact * sumAinv * (sumAinv.T * Xj)\n",
    "                CinvSum = sumAinv - fact * sumAinv * sumAinvSum\n",
    "                CinvTr = AinvTr - fact * sumAinv.T * sumAinv\n",
    "\n",
    "            Cinvy = Ainvy - fact * sumAinv * float(sumAinv.T * yj)\n",
    "            if not gradient:\n",
    "                logdetA = Nj * np.log(s_n) + logdetB\n",
    "                logdetC = logdetA + np.log(denom)\n",
    "\n",
    "        else :\n",
    "            C = s_w * kernel(Xj, Xj)\n",
    "            C = C + s_b + s_n * np.eye(Nj)\n",
    "            Cinv = np.linalg.pinv(C)\n",
    "            Cinvy = Cinv * yj\n",
    "            if gradient:\n",
    "                CinvX = Cinv * Xj\n",
    "                CinvTr = np.trace(Cinv)\n",
    "                CinvSum = Cinv.sum(axis=1)\n",
    "            else:\n",
    "                _, logdetC = np.linalg.slogdet(C)\n",
    "\n",
    "        if gradient:\n",
    "            return Cinvy, CinvSum, CinvX, CinvTr\n",
    "        else:\n",
    "            return Cinvy, logdetC\n",
    "\n",
    "    def log_likelihood_grad(self, ):\n",
    "        \"\"\"Computes the gradient of the log likelihood\"\"\"\n",
    "        s_w = self.lin_variance\n",
    "        s_b = self.bias_variance\n",
    "        s_n = self.white_variance\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\", self.X[[0, 1, 2], :])\n",
    "        # print(\"self.rated_items:\",self.rated_items,type(self.rated_items),self.rated_items.shape)\n",
    "        #到这会出问题。\n",
    "        #print(\"invert_covariance----self.X[self.rated_items, :]:\", self.X[self.rated_items,:])\n",
    "\n",
    "        yj = np.asmatrix(self.y).T\n",
    "        Xj = np.asmatrix(self.X[self.rated_items, :])\n",
    "        # Xj = np.asmatrix(self.X[int(self.rated_items), :])\n",
    "        # print(\"invert_covariance----self.X[self.rated_items, :]:\",self.X[self.rated_items, :])\n",
    "        Cinvy, CinvSum, CinvX, CinvTr = self.invert_covariance(gradient=True)\n",
    "        covGradX = 0.5 * (Cinvy * (Cinvy.T * Xj) - CinvX)\n",
    "        gX = s_w * 2.0 * covGradX\n",
    "        gsigma_w = np.multiply(covGradX, Xj).sum()\n",
    "        CinvySum = Cinvy.sum()\n",
    "        CinvSumSum = CinvSum.sum()\n",
    "        gsigma_b = 0.5 * (CinvySum * CinvySum - CinvSumSum)\n",
    "        gsigma_n = 0.5 * (Cinvy.T * Cinvy - CinvTr)\n",
    "        return gX, float(gsigma_w), float(gsigma_b), float(gsigma_n)\n",
    "\n",
    "    def objective(self):\n",
    "        return -self.log_likelihood()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f792e",
   "metadata": {},
   "source": [
    "Fit代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset, model, nb_iter=10, seed=42, momentum=0.9):\n",
    "    data = dataset.get_df()\n",
    "    param_init = np.zeros((1, 3))\n",
    "    X_init = np.zeros(model.X.shape)\n",
    "    for iter in range(nb_iter):\n",
    "        print(\"iteration：\", iter)\n",
    "        tic = time.time()\n",
    "        # 随机数要做什么？\n",
    "        np.random.seed(seed=seed)\n",
    "        state = np.random.get_state()\n",
    "        #每次随机生成的都一样，详见test.py\n",
    "        users = np.random.permutation(dataset.get_users())\n",
    "        #print(\"users:\",users.shape)\n",
    "\n",
    "        for user in users:\n",
    "            #print(\"begin user\", user,  \"=========================\")\n",
    "            toc = time.time()\n",
    "            lr = 1e-4\n",
    "            y = dataset.get_ratings_user(user)\n",
    "            #print(\"the user:\",user)\n",
    "            #print(\"y:\",y)\n",
    "            # rated_items = dataset.get_items_user(user) - 1\n",
    "            rated_items = dataset.get_items_user(user)\n",
    "            #print(\"rated_items:\",rated_items,\"type:\",type(rated_items))\n",
    "            model.y = y\n",
    "            #Ronchy将rated_items ndnumpy格式变成list\n",
    "            rated_items = list(rated_items)\n",
    "            #========================================\n",
    "            model.rated_items = rated_items\n",
    "            grad_X, grad_w, grad_b, grad_n = model.log_likelihood_grad()\n",
    "            gradient_param = np.array([grad_w * model.lin_variance,\n",
    "                               grad_b * model.bias_variance,\n",
    "                               grad_n * model.white_variance])\n",
    "            param = np.log(np.array([model.lin_variance,\n",
    "                                     model.bias_variance,\n",
    "                                     model.white_variance]))\n",
    "            # update X\n",
    "            X = X_init[rated_items, :]\n",
    "            ar = lr * 10\n",
    "            X = X * momentum + grad_X * ar\n",
    "            X_init[rated_items, :] = X\n",
    "            model.X[rated_items, :] = model.X[rated_items, :] + X\n",
    "\n",
    "            # update variances\n",
    "            param_init = param_init * momentum + gradient_param * lr\n",
    "            param = param + param_init\n",
    "            model.lin_variance = np.exp(param[0, 0])\n",
    "            model.bias_variance = np.exp(param[0, 1])\n",
    "            model.white_variance = np.exp(param[0, 2])\n",
    "            #print(\"end user\", user, \"=========================\")\n",
    "\n",
    "        print(\"end iteration\", iter,  \"=========================\")\n",
    "        print(\"duration iteration\", time.time() - tic)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744ed97",
   "metadata": {},
   "source": [
    "Predict代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61494793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, test_items, model, dataset):\n",
    "    y = dataset.get_ratings_user(user)\n",
    "    # rated_items = dataset.get_items_user(user) - 1\n",
    "    rated_items = dataset.get_items_user(user)\n",
    "    rated_items = list(rated_items)\n",
    "    model.rated_items = rated_items\n",
    "    model.y = y\n",
    "    X_test = np.asmatrix(model.X[test_items, :])\n",
    "    X = np.asmatrix(model.X[model.rated_items, :])\n",
    "    Cinvy, CinvSum, CinvX, CinvTr = model.invert_covariance(gradient=True)\n",
    "    mean = model.lin_variance* X_test*(X.T*Cinvy) + Cinvy.sum() * model.bias_variance\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335469d",
   "metadata": {},
   "source": [
    "执行代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a56570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_weak(dataset, base_dim=5):\n",
    "    print('Fetch data set...')\n",
    "    # if dataset.dataset == \"movielens\":\n",
    "    #     norm_coeff = 1.6\n",
    "    #     print(\"norm_coeff:1.6------------\")\n",
    "    # else :\n",
    "    #     norm_coeff = 6.67\n",
    "    norm_coeff = 1.6\n",
    "    print('Data set fetched')\n",
    "    # print(\"Dataset desctiption\", dataset.get_description())\n",
    "    model_init = GpMf(latent_dim=base_dim, nb_data=dataset.item_index_range)\n",
    "    print('Fit the model...')\n",
    "    model = fit(dataset=dataset, model=model_init)\n",
    "    print('Model fitted')\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    test_users = dataset.get_users_test()\n",
    "\n",
    "    nb_users_test = len(test_users)\n",
    "    print(\"nb_users_test\", nb_users_test)\n",
    "    count = 0\n",
    "    for user in test_users:\n",
    "        prediction = predict(user, dataset.get_item_test(user), model, dataset)\n",
    "        if prediction > dataset.high_rating:\n",
    "            prediction = dataset.high_rating\n",
    "        if prediction < dataset.low_rating:\n",
    "            prediction = dataset.low_rating\n",
    "        predictions.append(prediction)\n",
    "        rating = dataset.get_rating_test(user)\n",
    "        true_ratings.append(rating)\n",
    "        count += 1\n",
    "        #print(count, \"over \", nb_users_test, \"users\")\n",
    "    predictions = np.asarray(predictions)\n",
    "    true_ratings = np.asarray(true_ratings)\n",
    "    #误差计算\n",
    "    rmse = np.linalg.norm(predictions - true_ratings) / np.sqrt(nb_users_test)\n",
    "    nmae = np.sum(np.abs(true_ratings - predictions)) * 1. / (len(predictions) * norm_coeff)\n",
    "    print(\"rmse\", rmse)\n",
    "    print(\"nmae\", nmae)\n",
    "    return float(rmse), float(nmae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c47314",
   "metadata": {},
   "source": [
    "画图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb349e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_vs_latent_dims():\n",
    "    base_dims = range(3, 10)  #latent feature ,3的时候最好\n",
    "    rmse_res = []\n",
    "        #0.9192805345815771, 0.9191762806556765, 0.9298582192495648, 0.9264887573748214, 0.942721413670847,\n",
    "        #0.9464276649204383, 0.9619938797137044, 0.959524838407498, 0.9637647705458857, 0.9654112679112156,\n",
    "        #0.964014562524729, 0.9828162923399141, 0.9791815989138641, 0.9755912980143179, 0.9909916313775403]\n",
    "    nmae_res = []\n",
    "        #0.44971496453721255, 0.44916990674349777, 0.4520802986328138, 0.45121143493891314, 0.45841600020196077,\n",
    "        #0.4600831341641973, 0.46819195277564857, 0.4653186575931832, 0.4675059307434209, 0.46521752440367997,\n",
    "        #0.4693989965956004, 0.4749311584164483, 0.47302261002602103, 0.47072878663284334, 0.4775780782441432]\n",
    "\n",
    "    if not len(rmse_res):\n",
    "        dataset_Corner = DataSet(dataset=\"Corner\", size=\"14\")\n",
    "        for dim in base_dims:\n",
    "            print(\"the latent-feature:\",dim)\n",
    "            (rmse, nmae) = perf_weak(dataset=dataset_Corner, base_dim=dim)\n",
    "            rmse_res.append(rmse)\n",
    "            nmae_res.append(nmae)\n",
    "\n",
    "        print(rmse_res)\n",
    "        print(nmae_res)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, rmse_res, marker='.')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('RMSE (MovieLens 100k)')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base_dims, nmae_res, marker='*')\n",
    "    plt.xlabel('Number of latent dimensions ($r$)')\n",
    "    plt.ylabel('NMAE (MovieLens 100k)')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('START')\n",
    "    perf_weak(dataset=DataSet(dataset=\"Corner\", size=\"14\"))\n",
    "\n",
    "    # plot_errors_vs_latent_dims()\n",
    "    print('END')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
